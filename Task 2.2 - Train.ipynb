{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86a3b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "from keras.layers import Input, Dense, Dropout,\\\n",
    "Conv2D, MaxPooling2D, Flatten, Activation, BatchNormalization, Conv2DTranspose, concatenate\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65649f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_conv_block(x, n_filters):\n",
    "    x = Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
    "    x = Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
    "    return x\n",
    "\n",
    "def downsample_block(x, n_filters):\n",
    "    f = double_conv_block(x, n_filters)\n",
    "    p = MaxPooling2D(2)(f)\n",
    "    p = Dropout(0.4)(p)\n",
    "    return f, p\n",
    "\n",
    "def upsample_block(x, conv_features, n_filters):\n",
    "    x = Conv2DTranspose(n_filters, 3, 2, padding=\"same\")(x)\n",
    "    x = concatenate([x, conv_features])\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = double_conv_block(x, n_filters)\n",
    "\n",
    "    return x\n",
    "\n",
    "def build_unet_model():    \n",
    "    inputs = Input(shape=(80,48,1))\n",
    "    init_n_filters = 16\n",
    "\n",
    "    f1, p1 = downsample_block(inputs, init_n_filters)\n",
    "    f2, p2 = downsample_block(p1, 2*init_n_filters)\n",
    "    f3, p3 = downsample_block(p2, 4*init_n_filters)\n",
    "    f4, p4 = downsample_block(p3, 4*init_n_filters)\n",
    "\n",
    "    bottleneck = double_conv_block(p4, 8*init_n_filters)\n",
    "\n",
    "    u6 = upsample_block(bottleneck, f4, 4*init_n_filters)\n",
    "    u7 = upsample_block(u6, f3, 4*init_n_filters)\n",
    "    u8 = upsample_block(u7, f2, 2*init_n_filters)\n",
    "    u9 = upsample_block(u8, f1, init_n_filters)\n",
    "\n",
    "    outputs = Conv2D(1, 1, padding=\"same\", activation = \"sigmoid\")(u9)\n",
    "    unet_model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return unet_model\n",
    "\n",
    "unet_model = build_unet_model()\n",
    "unet_model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.MeanSquaredError(),\n",
    "              metrics=['MSE'])\n",
    "unet_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98db41eb",
   "metadata": {},
   "source": [
    "Для обучения изменить пути до соответствующих частей датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f62a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_clean = \"C:/Users/a.aspidov/Desktop/attachments/train/clean\"\n",
    "path_noisy = \"C:/Users/a.aspidov/Desktop/attachments/train/noisy\"\n",
    "path_val_clean = \"C:/Users/a.aspidov/Desktop/attachments/val/val/clean/\"\n",
    "path_val_noisy = \"C:/Users/a.aspidov/Desktop/attachments/val/val/noisy/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e990a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_samples(samples_raw):\n",
    "    mod = [s - s.min() for s in samples_raw]\n",
    "    mod = [(s / s.max()).T for s in mod]\n",
    "    \n",
    "    min_len = 48\n",
    "    normalized = []\n",
    "\n",
    "    for s in mod:\n",
    "        if s.shape[1] % min_len == 0:\n",
    "            normalized += [s[:, min_len * i:min_len * (i + 1)] for i in range(s.shape[1] // min_len)]\n",
    "        else:\n",
    "            normalized += [s[:, min_len * i:min_len * (i + 1)] for i in range(s.shape[1] // min_len + 1)]\n",
    "            normalized[-1] = np.pad(normalized[-1], ((0, 0), (0, min_len - s.shape[1] % min_len)), 'constant')\n",
    "    return np.array(normalized)\n",
    "\n",
    "def load_dataset_part(path_base):\n",
    "    path_list = [os.path.join(path_base, speaker, file) for speaker in\n",
    "                os.listdir(path_base) for file in\n",
    "                os.listdir(os.path.join(path_base, speaker))]\n",
    "    mel_list = [np.load(path) for path in path_list]\n",
    "    return mel_list\n",
    "\n",
    "x_train = load_dataset_part(path_noisy)\n",
    "y_train = load_dataset_part(path_clean)\n",
    "x_train = normalize_samples(x_train)\n",
    "y_train = normalize_samples(y_train)\n",
    "\n",
    "x_val = load_dataset_part(path_val_noisy)\n",
    "y_val = load_dataset_part(path_val_clean)\n",
    "x_val = normalize_samples(x_val)\n",
    "y_val = normalize_samples(y_val)\n",
    "\n",
    "assert x_train.shape == y_train.shape\n",
    "assert x_val.shape == y_val.shape\n",
    "\n",
    "x_train = x_train[..., np.newaxis]\n",
    "y_train = y_train[..., np.newaxis]\n",
    "\n",
    "x_val = x_val[..., np.newaxis]\n",
    "y_val = y_val[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6749f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 30\n",
    "history = unet_model.fit(x_train, y_train, validation_data=(x_val, y_val), verbose=2, epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abee9ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = history.history['MSE']\n",
    "val_mse = history.history['val_MSE']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23922235",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.style.use('ggplot')\n",
    "plt.plot(range(n_epochs), loss, label='loss')\n",
    "plt.plot(range(n_epochs), val_loss, label='val_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90efaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(range(n_epochs), mse, label='MSE')\n",
    "plt.plot(range(n_epochs), val_mse, label='val_MSE')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a0e139",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_model.save('model_22.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
